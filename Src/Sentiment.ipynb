{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099ceb9-5133-4e4e-827c-fc6e11be2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a9fb1-2b67-42f1-87bc-b4ed15c7b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv',\n",
    "    '1429_1.csv'\n",
    "]\n",
    "selected_columns = ['text', 'rating']\n",
    "\n",
    "\n",
    "dfs = [pd.read_csv(file, usecols=selected_columns) for file in files]\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48a7f2-5c6b-4b54-8f48-176f57d15096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd445d86-a0dd-4e8c-8af7-80110a023733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['rating'] = df['rating'].fillna(df['rating'].median())df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16443d-5f97-4c66-b618-f3a0ebdb050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75ff80-1c5e-4708-a1ed-5b5918480f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d0ebf-6c98-4d36-94e1-c42d9a639e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 'negative'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(label_sentiment)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b5578-b35b-4afe-8c69-79bab9121f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# -----------------------------\n",
    "# Load spaCy model efficiently\n",
    "# -----------------------------\n",
    "# Disable parser and NER for speed, only use tokenizer & tagger\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Precompile regex for cleaning\n",
    "# -----------------------------\n",
    "RE_CLEAN = re.compile(r'[^a-zA-Z\\s]')  # keep only letters and spaces\n",
    "\n",
    "# -----------------------------\n",
    "# Function to clean a single doc\n",
    "# -----------------------------\n",
    "def clean_doc(doc):\n",
    "    tokens = [\n",
    "        token.lemma_  # lemmatize\n",
    "        for token in doc\n",
    "        if token.is_alpha and token.text not in STOP_WORDS\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare text column\n",
    "# -----------------------------\n",
    "texts = df_clean['text'].astype(str).str.lower().tolist()  # lowercase all\n",
    "\n",
    "# -----------------------------\n",
    "# Batch process using spaCy pipe\n",
    "# -----------------------------\n",
    "# Adjust batch_size and n_process based on dataset size and CPU cores\n",
    "cleaned_texts = [\n",
    "    clean_doc(doc)\n",
    "    for doc in nlp.pipe(texts, batch_size=1000, n_process=2)\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned text back to DataFrame\n",
    "# -----------------------------\n",
    "df_clean['clean_text'] = cleaned_texts\n",
    "\n",
    "# -----------------------------\n",
    "# Quick check\n",
    "# -----------------------------\n",
    "print(df_clean[['text', 'clean_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4225db-c63d-4458-8f59-7c7a46e3320e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
